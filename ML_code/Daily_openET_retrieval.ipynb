{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# la.explode(index_parts=False)\n",
    "import random\n",
    "from shapely.geometry import Polygon,Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access token\n",
    "api_key = \"R6Hv0RU5drMtW39Ci45p9ytQCsQSHJq7NXSMK0tPuMfhI5GkfgKNRkbjszp8\"\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# remove warning message\n",
    "requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "def call_api(endpoint, api_key, args, get=True):\n",
    "    \"\"\"Using user specified inputs, returns data from OpenET Raster API.\n",
    "\n",
    "    Args:\n",
    "        endpoint (str): Raster API endpoint\n",
    "\n",
    "        api_key (str): Required api access key\n",
    "\n",
    "        args (dictionary): User specified arguments for api call\n",
    "\n",
    "    Returns:\n",
    "        result (object): An object of Raster API results\n",
    "    \"\"\"\n",
    "\n",
    "    # api server address\n",
    "    server = 'https://openet-api.org/'\n",
    "\n",
    "    # initialize request url\n",
    "    url = server + endpoint\n",
    "\n",
    "    # create header\n",
    "    header = {\"Authorization\": api_key}\n",
    "\n",
    "    if get:\n",
    "        # make api get request\n",
    "        resp = requests.get(url=url, headers=header, params=args, verify=False)\n",
    "\n",
    "    else: \n",
    "        # make api post request\n",
    "        resp = requests.post(url=url, headers=header, data=json.dumps(args), verify=False)\n",
    "\n",
    "    # view results\n",
    "    return resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_et_call(day1,day2,lon,lat):\n",
    "    # geodatbase api endpoint\n",
    "  endpoint = \"/raster/timeseries/point\"\n",
    "\n",
    "  # endpoint arguments\n",
    "  args = {\n",
    "    \"date_range\": [\n",
    "      day1,day2\n",
    "    ],\n",
    "    \"interval\": \"daily\",\n",
    "    \"geometry\": [lon,lat],\n",
    "    \"model\": \"ensemble\",\n",
    "    \"variable\": \"et\",\n",
    "    \"reference_et\": \"gridMET\",\n",
    "    \"reducer\": \"mean\",\n",
    "    \"units\": \"mm\",\n",
    "    \"file_format\": \"JSON\"\n",
    "  }\n",
    "  # query result\n",
    "  response = call_api(endpoint, api_key, args, get=False)\n",
    "\n",
    "  # cast into a dictionary\n",
    "  response = json.loads(response)\n",
    "  print(response)\n",
    "  return pd.DataFrame.from_dict(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start dates:\n",
      "['2021-02-20', '2021-02-21', '2021-02-22', '2021-02-23', '2021-02-24', '2021-02-25', '2021-02-26', '2021-02-27', '2021-02-28', '2021-03-01', '2021-03-02', '2021-03-03', '2021-03-04']\n",
      "\n",
      "End dates:\n",
      "['2021-02-21', '2021-02-22', '2021-02-23', '2021-02-24', '2021-02-25', '2021-02-26', '2021-02-27', '2021-02-28', '2021-03-01', '2021-03-02', '2021-03-03', '2021-03-04', '2021-03-05']\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from collections import OrderedDict\n",
    "from calendar import monthrange\n",
    "def split_years_by_day(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Function to split query period into smaller periods with a difference of one day between start and end dates\n",
    "    Takes input as start and end dates in the format 'YYYY-MM-DD'\n",
    "    Returns lists of start and end periods for each day\n",
    "    \"\"\"\n",
    "\n",
    "    start, end = [datetime.strptime(_, \"%Y-%m-%d\") for _ in [start_date, end_date]]\n",
    "    start = [(start + timedelta(_)).strftime(r\"%Y-%m-%d\") for _ in range((end - start).days)]\n",
    "    end = [(datetime.strptime(item, \"%Y-%m-%d\") + timedelta(days=1)).strftime(r\"%Y-%m-%d\") for item in start]\n",
    "    return start, end\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "start_dates, end_dates = split_years_by_day(\"2021-02-20\", \"2021-03-05\")\n",
    "print(\"Start dates:\")\n",
    "print(start_dates)\n",
    "print(\"\\nEnd dates:\")\n",
    "print(end_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regualar Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Backup\\\\Rouhin_Lenovo\\\\US_project\\\\Untitled_Folder\\\\Data\\\\Volk_merged\\\\ML_datasets\\\\Val_Data_for_OpenET\\\\US-xSB.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tmp\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mBackup\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mRouhin_Lenovo\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUS_project\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUntitled_Folder\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mData\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mVolk_merged\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mML_datasets\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mVal_Data_for_OpenET\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUS-xSB.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tmp\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      3\u001b[0m tmp\u001b[38;5;241m=\u001b[39mtmp[tmp\u001b[38;5;241m.\u001b[39mDate\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2016\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rouhi\\anaconda3\\envs\\rs\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rouhi\\anaconda3\\envs\\rs\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\rouhi\\anaconda3\\envs\\rs\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rouhi\\anaconda3\\envs\\rs\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\rouhi\\anaconda3\\envs\\rs\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Backup\\\\Rouhin_Lenovo\\\\US_project\\\\Untitled_Folder\\\\Data\\\\Volk_merged\\\\ML_datasets\\\\Val_Data_for_OpenET\\\\US-xSB.csv'"
     ]
    }
   ],
   "source": [
    "tmp=pd.read_csv(\"D:\\\\Backup\\\\Rouhin_Lenovo\\\\US_project\\\\Untitled_Folder\\\\Data\\\\Volk_merged\\\\ML_datasets\\\\Val_Data_for_OpenET\\\\US-xSB.csv\",parse_dates=[\"Date\"])\n",
    "print(tmp.head())\n",
    "tmp=tmp[tmp.Date.dt.year>=2016]\n",
    "a,b=split_years_by_day(tmp[\"Date\"].iloc[0].date().strftime('%Y-%m-%d'),(tmp[\"Date\"].iloc[0]+timedelta(days=1)).strftime('%Y-%m-%d'))\n",
    "# tmp[\"Date\"].iloc[0]+datetime.timedelta(days=10)\n",
    "b\n",
    "# t.\n",
    "# tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_0\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_1\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_2\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_3\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_4\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_5\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_6\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_7\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_8\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_9\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_10\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_11\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_12\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_13\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_14\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_15\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_16\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_17\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m     master_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mBackup\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mRouhin_Lenovo\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUS_project\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUntitled_Folder\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mData\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mVolk_merged\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mML_datasets\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOpen_ET\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSite_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m master_df\n\u001b[1;32m---> 18\u001b[0m \u001b[43marange_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[40], line 13\u001b[0m, in \u001b[0;36marange_call\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror opening some_file_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m master_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_api\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     14\u001b[0m master_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETa\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat(sub_api)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124met\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# master_df[\"Area_ws_\"+str(i)]=area_df[\"area\"].iloc[i]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rouhi\\anaconda3\\envs\\rs\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    370\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\rouhi\\anaconda3\\envs\\rs\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:429\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    426\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    432\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "api_key = \"R6Hv0RU5drMtW39Ci45p9ytQCsQSHJq7NXSMK0tPuMfhI5GkfgKNRkbjszp8\"\n",
    "def arange_call(df):\n",
    "    master_df=pd.DataFrame()\n",
    "    sub_api=[]\n",
    "    for i in range(0,df.shape[0]):\n",
    "        print(\"Site=\" , df[\"Site_name\"].iloc[0])\n",
    "        start_date,end_date=split_years_by_day(tmp[\"Date\"].iloc[i].date().strftime('%Y-%m-%d'),(tmp[\"Date\"].iloc[i]+timedelta(days=1)).strftime('%Y-%m-%d'))\n",
    "        try:\n",
    "            sub_api.append(open_et_call(start_date[0],end_date[0],df[\"Lon_volk\"].iloc[i],df[\"Lat_volk\"].iloc[i]))\n",
    "        except Exception as e:\n",
    "            print(f\"error opening some_file_{i}\")\n",
    "            continue\n",
    "    master_df[\"Date\"]=pd.concat(sub_api)[\"time\"]\n",
    "    master_df[\"ETa\"]=pd.concat(sub_api)[\"et\"]\n",
    "    # master_df[\"Area_ws_\"+str(i)]=area_df[\"area\"].iloc[i]\n",
    "    master_df.to_csv(\"D:\\\\Backup\\\\Rouhin_Lenovo\\\\US_project\\\\Untitled_Folder\\\\Data\\\\Volk_merged\\\\ML_datasets\\\\Open_ET\\\\\"+df[\"Site_name\"].iloc[0]+\".csv\")\n",
    "    return master_df\n",
    "arange_call(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For sen1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0  Unnamed: 0_x       Date         B         R  \\\n",
      "0             0          19          32.0 2015-04-17  0.031523  0.055640   \n",
      "1             1          22          35.0 2015-06-20  0.019918  0.023492   \n",
      "2             2          24          36.0 2015-07-22  0.024867  0.023135   \n",
      "3             3          26          39.0 2015-09-24  0.015655  0.026682   \n",
      "4             4          30          42.0 2016-01-14 -0.007225  0.022365   \n",
      "\n",
      "         GR       NIR    SWIR_1    SWIR_2  ...    VH_green      VH_blue  \\\n",
      "0  0.052202  0.184505  0.187475  0.112372  ... -202.403586  -335.188300   \n",
      "1  0.040130  0.286640  0.143530  0.058197  ... -269.463697  -542.918446   \n",
      "2  0.041092  0.299538  0.150927  0.060067  ... -324.712962  -536.574541   \n",
      "3  0.035428  0.217257  0.111245  0.052065  ... -355.096793  -803.589374   \n",
      "4  0.018460  0.140037  0.096945  0.059298  ... -529.881007  1353.855142   \n",
      "\n",
      "      VH_NIR    VH_SWIR1    VH_SWIR2    VH_NDVI    VH_NDWI    VH_LST  \\\n",
      "0 -57.266595  -56.359372  -94.026325 -19.690107  18.903990 -0.034984   \n",
      "1 -37.725294  -75.340195 -185.808293 -12.744343  14.334319 -0.035922   \n",
      "2 -44.546233  -88.408457 -222.137885 -15.576941  17.586400 -0.043701   \n",
      "3 -57.904522 -113.085457 -241.624731 -16.102909  17.482405 -0.042327   \n",
      "4 -69.849886 -100.898483 -164.958108 -13.499814  12.752028 -0.034936   \n",
      "\n",
      "     VV_LST     VH-VV  \n",
      "0 -0.021007 -4.221372  \n",
      "1 -0.027033 -2.675730  \n",
      "2 -0.013516 -9.216343  \n",
      "3 -0.027176 -4.502926  \n",
      "4 -0.035020  0.023606  \n",
      "\n",
      "[5 rows x 62 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2016-01-15']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"D:\\\\Backup\\\\Rouhin_Lenovo\\\\US_project\\\\Untitled_Folder\\\\Data\\\\Volk_merged\\\\ML_datasets\\\\Val_Data_for_OpenET\\\\Sen1\")\n",
    "file_list=os.listdir()\n",
    "# tmp=pd.read_csv(\"D:\\\\Backup\\\\Rouhin_Lenovo\\\\US_project\\\\Untitled_Folder\\\\Data\\\\Volk_merged\\\\ML_datasets\\\\Val_Data_for_OpenET\\\\Sen1\\\\JPL1_JV114.csv\",parse_dates=[\"Date\"])\n",
    "tmp=pd.read_csv(file_list[9],parse_dates=[\"Date\"])\n",
    "\n",
    "print(tmp.head())\n",
    "tmp=tmp[tmp.Date.dt.year>=2016]\n",
    "a,b=split_years_by_day(tmp[\"Date\"].iloc[0].date().strftime('%Y-%m-%d'),(tmp[\"Date\"].iloc[0]+timedelta(days=1)).strftime('%Y-%m-%d'))\n",
    "# tmp[\"Date\"].iloc[0]+datetime.timedelta(days=10)\n",
    "b\n",
    "# t.\n",
    "# tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_0\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_1\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_2\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_3\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_4\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_5\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_6\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_7\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_8\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_9\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_10\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_11\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_12\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_13\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_14\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_15\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_16\n",
      "Site= US-MOz\n",
      "{'detail': 'Monthly request limit has been reached. Please wait until the 1st midnight UTC for reset.'}\n",
      "error opening some_file_17\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m     master_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mBackup\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mRouhin_Lenovo\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUS_project\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUntitled_Folder\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mData\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mVolk_merged\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mML_datasets\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOpen_ET\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSen1\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSite_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m master_df\n\u001b[1;32m---> 18\u001b[0m \u001b[43marange_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[56], line 13\u001b[0m, in \u001b[0;36marange_call\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror opening some_file_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m master_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_api\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     14\u001b[0m master_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETa\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat(sub_api)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124met\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# master_df[\"Area_ws_\"+str(i)]=area_df[\"area\"].iloc[i]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rouhi\\anaconda3\\envs\\rs\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    370\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\rouhi\\anaconda3\\envs\\rs\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:429\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    426\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    432\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "api_key = \"R6Hv0RU5drMtW39Ci45p9ytQCsQSHJq7NXSMK0tPuMfhI5GkfgKNRkbjszp8\"\n",
    "def arange_call(df):\n",
    "    master_df=pd.DataFrame()\n",
    "    sub_api=[]\n",
    "    for i in range(0,df.shape[0]):\n",
    "        print(\"Site=\" , df[\"Site_name\"].iloc[0])\n",
    "        start_date,end_date=split_years_by_day(tmp[\"Date\"].iloc[i].date().strftime('%Y-%m-%d'),(tmp[\"Date\"].iloc[i]+timedelta(days=1)).strftime('%Y-%m-%d'))\n",
    "        try:\n",
    "            sub_api.append(open_et_call(start_date[0],end_date[0],df[\"Lon_volk\"].iloc[i],df[\"Lat_volk\"].iloc[i]))\n",
    "        except Exception as e:\n",
    "            print(f\"error opening some_file_{i}\")\n",
    "            continue\n",
    "    master_df[\"Date\"]=pd.concat(sub_api)[\"time\"]\n",
    "    master_df[\"ETa\"]=pd.concat(sub_api)[\"et\"]\n",
    "    # master_df[\"Area_ws_\"+str(i)]=area_df[\"area\"].iloc[i]\n",
    "    master_df.to_csv(\"D:\\\\Backup\\\\Rouhin_Lenovo\\\\US_project\\\\Untitled_Folder\\\\Data\\\\Volk_merged\\\\ML_datasets\\\\Open_ET\\\\Sen1\\\\\"+df[\"Site_name\"].iloc[0]+\".csv\")\n",
    "    return master_df\n",
    "arange_call(tmp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
